---
title: "04. Linear&Multi Regression(회귀)"
categories: Machine_Learning
tag: [python, machine_learning, concept]
toc: true
toc_sticky: true
author_profile: false
sidebar:
  nav: "docs"
typora-root-url: ../../..
---



**다중 회귀 분석은 여러 독립변수가 종속변수에 미치는 영향을 분석하는 통계적 방법으로, 이 글에서는 선형 회귀와 다중 회귀의 개념, 해석학적/대수적 접근법을 통한 회귀 계수 유도 과정, 그리고 L1/L2 정규화를 포함한 다양한 회귀 모델(Linear, Ridge, Lasso, Elastic Net)에 대해 설명합니다.**

<br>

**ML/DL 은 분류, 추론으로 크게 동작을 나눠볼 수 있다.**

![image-20230420013251328](/images/2023-04-17-04. Linear&Multi Regression(회귀)/image-20230420013251328.png) 

<br>

**이번 포스팅에서는 회귀를 소개한다.**

<br><br>

# Linear Regression(선형회귀)

**Loss가 최소인것을 구하는게 중요한데 이 Loss 함수에는 예측값 y가 필요하다.**

**예측값 y는 w, b가 필요하며 이를 유도하는 공식들을 살펴본다.**

![image-20230420013347558](/images/2023-04-17-04. Linear&Multi Regression(회귀)/image-20230420013347558.png) 

<br><br>

## 1. 해석학적 접근법

**알파, 베타를 구하는 유도과정**

![image-20230420013740594](/images/2023-04-17-04. Linear&Multi Regression(회귀)/image-20230420013740594.png) 

![image-20230420013905033](/images/2023-04-17-04. Linear&Multi Regression(회귀)/image-20230420013905033.png) 

<br>

**책에서의 공식(베타가 좀 다름. 물론 의미는 동일한 공식)** 

* 따라서 아래그림은 책의 공식 베타로 위의 원래 공식 베타를 유도하는 과정을 나타낸다.

![image-20230420013945024](/images/2023-04-17-04. Linear&Multi Regression(회귀)/image-20230420013945024.png) 

<br><br>

## 2. 대수적 접근법

**해석학적이 아닌 이번엔 대수적 방법으로 유도하는 과정 (세타를 구한다)**

![image-20230420014155202](/images/2023-04-17-04. Linear&Multi Regression(회귀)/image-20230420014155202.png) 

![image-20230420014219570](/images/2023-04-17-04. Linear&Multi Regression(회귀)/image-20230420014219570.png) 

<br>

### 예제

![image-20230420014239578](/images/2023-04-17-04. Linear&Multi Regression(회귀)/image-20230420014239578.png) 

<br><br>

## 3. 필요 배경지식

**행렬 제곱, 전치 행렬, 벡터의 편미분 특징을 알아야 한다.**

**특히 벡터의 편미분 특징이 생소할 것이니까 이를 잘 이해하자.**

![image-20230420014355244](/images/2023-04-17-04. Linear&Multi Regression(회귀)/image-20230420014355244.png) 

![image-20230420014432953](/images/2023-04-17-04. Linear&Multi Regression(회귀)/image-20230420014432953.png) 

<br>

### 예제

**점과 직선 사이의 거리 d 공식은 그냥 보여주는것이다.**

![image-20230420014459929](/images/2023-04-17-04. Linear&Multi Regression(회귀)/image-20230420014459929.png) 

<br><br>

# Multi Regression(다중회귀)

**단일, 다중을 구분하는건 독립변수 1개냐 여러개냐로 구분!**

**다중회귀도 단일선형에서 보여준 공식들 똑같이 사용한다.**

![image-20230420014731671](/images/2023-04-17-04. Linear&Multi Regression(회귀)/image-20230420014731671.png) 

<br>

## Regression & L1/L2 Regularization 

**회귀 & L1/L2 정규화를 사용해서 공식들을 나타내 보겠다.**

* ㅠㅠ 글자가 너무 악필이다보니 자세한 공식은 구글링을 참조
* Linear, Ridge, Lasso, Elastic Regression 입니다.

![image-20230420015320182](/images/2023-04-17-04. Linear&Multi Regression(회귀)/image-20230420015320182.png) 

